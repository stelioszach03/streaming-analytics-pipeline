version: '3'

# Add explicit network configuration
networks:
  streaming-net:
    driver: bridge

services:
  # ===== Infrastructure Services =====
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - streaming-net
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      interval: 10s
      retries: 3
      start_period: 10s
      timeout: 10s

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Fix for message size issue - increasing to 1GB
      KAFKA_MESSAGE_MAX_BYTES: 1073741824
      KAFKA_REPLICA_FETCH_MAX_BYTES: 1073741824
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 1073741824
      # Added for consumer and producer
      KAFKA_CONSUMER_MAX_PARTITION_FETCH_BYTES: 1073741824
      KAFKA_PRODUCER_MAX_REQUEST_SIZE: 1073741824
    networks:
      - streaming-net
    healthcheck:
      test: kafka-topics --bootstrap-server kafka:9093 --list || exit 1
      interval: 10s
      retries: 5
      start_period: 20s
      timeout: 10s

  kafka-setup:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka-setup
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - streaming-net
    command: >
      bash -c "
        echo 'Waiting for Kafka to be available...'
        sleep 20
        echo 'Creating Kafka topics...'
        kafka-topics --bootstrap-server kafka:9093 --create --if-not-exists --topic metrics-data --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:9093 --create --if-not-exists --topic processed-metrics --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:9093 --create --if-not-exists --topic alerts --partitions 3 --replication-factor 1
        kafka-topics --bootstrap-server kafka:9093 --create --if-not-exists --topic service-health --partitions 3 --replication-factor 1
        echo 'Topics created.'
      "

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.10
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - streaming-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  cassandra:
    image: cassandra:4.1
    container_name: cassandra
    ports:
      - "9042:9042"
    environment:
      MAX_HEAP_SIZE: 256M
      HEAP_NEWSIZE: 128M
      CASSANDRA_CLUSTER_NAME: MetricsCluster
    volumes:
      - ./storage/cassandra/schema/schema.cql:/schema.cql
    networks:
      - streaming-net
    healthcheck:
      test: cqlsh -e "describe keyspaces" || exit 1
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  cassandra-setup:
    image: cassandra:4.1
    container_name: cassandra-setup
    depends_on:
      cassandra:
        condition: service_healthy
    networks:
      - streaming-net
    command: >
      bash -c "
        echo 'Waiting for Cassandra to be ready...'
        sleep 60
        echo 'Initializing schema...'
        cqlsh cassandra -f /schema.cql
        echo 'Schema initialized.'
      "
    volumes:
      - ./storage/cassandra/schema/schema.cql:/schema.cql

  # ===== Application Services =====
  kafka-producer:
    build:
      context: ./ingestion/producer
    container_name: kafka-producer
    depends_on:
      kafka:
        condition: service_healthy
      kafka-setup:
        condition: service_completed_successfully
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9093
      KAFKA_TOPIC: metrics-data
      SERVICE_NAME: system-monitor
      REGION: us-east
    networks:
      - streaming-net

  # ===== Processing Services =====
  flink-jobmanager:
    image: flink:1.17.0-scala_2.12-java11
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
        jobmanager.execution.failover-strategy: region
        restart-strategy: fixed-delay
        restart-strategy.fixed-delay.attempts: 3
        restart-strategy.fixed-delay.delay: 10s
    networks:
      - streaming-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/overview"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 20s

  flink-taskmanager:
    image: flink:1.17.0-scala_2.12-java11
    container_name: flink-taskmanager
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
    networks:
      - streaming-net

  flink-metrics-job:
    build:
      context: ./processing/flink-jobs
    container_name: flink-metrics-job
    depends_on:
      flink-jobmanager:
        condition: service_healthy
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    environment:
      FLINK_JOBMANAGER_HOST: flink-jobmanager
      FLINK_JOBMANAGER_PORT: 8081
      KAFKA_BOOTSTRAP_SERVERS: kafka:9093
      KAFKA_SOURCE_TOPIC: metrics-data
      KAFKA_SINK_TOPIC: processed-metrics
      KAFKA_ALERTS_TOPIC: alerts
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
    networks:
      - streaming-net
    restart: on-failure

  # ===== API Gateway =====
  api-gateway:
    build:
      context: ./api-gateway
    container_name: api-gateway
    ports:
      - "8080:8080"
    environment:
      PORT: 8080
      KAFKA_BOOTSTRAP_SERVERS: kafka:9093
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - streaming-net
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8080/actuator/health || exit 1
      interval: 20s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ===== Frontend Service =====
  frontend:
    build:
      context: ./frontend
    container_name: frontend
    ports:
      - "80:80"
    environment:
      REACT_APP_WEBSOCKET_URL: ws://localhost:8080/ws
    depends_on:
      api-gateway:
        condition: service_healthy
    networks:
      - streaming-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # ===== Monitoring Services =====
  prometheus:
    image: prom/prometheus:v2.43.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/rules:/etc/prometheus/rules
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    depends_on:
      api-gateway:
        condition: service_healthy
    networks:
      - streaming-net

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    restart: unless-stopped
    networks:
      - streaming-net

  grafana:
    image: grafana/grafana:9.4.7
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/dashboards
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      prometheus:
        condition: service_started
    networks:
      - streaming-net

volumes:
  esdata:
    driver: local